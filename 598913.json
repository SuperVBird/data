{"id":598913,"link":"https://chinadigitaltimes.net/chinese/2018/11/端传媒-徐子轩：ai预测犯罪，谁会成为人工智能的/","date":"2018-11-03T22:02:33Z","modified":"2018-11-03T22:06:34Z","title":"端传媒 | 徐子轩：AI预测犯罪，谁会成为人工智能的眼中钉？","content":"<p><strong>CDT编辑注：本文为端传媒付费文章节选，阅读全文请订阅端传媒。</strong></p>\n<p>作者：徐子轩，LUCIO策略顾问总监，淡江大学国际事务与战略研究所博士</p>\n<p>十多年前，好莱坞名导史匹堡（史匹柏，斯皮尔伯格）翻拍了1950年代的科幻小说，电影叫做《关键报告》（Minority Report，港译“未来报告”，中国大陆译“少数派报告”），内容是描述未来某国政府利用变异人类的超能力，预测潜在犯罪（pre-crime），以便司法系统提前阻止。因此，这样的社会没有重大罪行，只有充满“潜在罪犯”的拘留营，一切看似安和乐利。</p>\n<p>这类电影寓言凸显长久以来，人类虽想预测犯罪，却弄巧成拙的荒谬。如今现实生活中，许多国家面对层出不穷的犯罪问题，正在使用或引入属于它们的“少数报告”。不过，它们依靠的并非是超能力人类，而是人工智慧（AI）。</p>\n<p>由于AI的兴起，给了学者专家突破的机会，尝试统合犯罪学、人口学、地震学等学科，以及浩瀚无垠的案件资料，让机器进行深度学习，找出人类无法预见的部分。</p>\n<p>事实上，在我们的生活里，已经充满著监视器与人脸辨识系统，警务机关可借由AI筛选“危险人物”。这跟AI预测犯罪有何不同？使用AI预测背后，又是否会产生一些AI与人类无法处理的问题？</p>\n<div id=\"attachment_598914\" style=\"width: 610px\" class=\"wp-caption alignnone\"><img class=\"size-full wp-image-598914\" src=\"https://chinadigitaltimes.net/chinese/files/2018/11/Screen-Shot-2018-11-03-at-5.59.18-PM-e1541282420880.png\" alt=\"\" width=\"600\" height=\"398\" /><p class=\"wp-caption-text\">随著深度学习的进化，AI预测犯罪的准确度或许能逐步提升，但实际上可能无法预防犯罪。摄：Steffi Loos/Getty Images</p></div>\n<p>[&#8230;]</p>\n<p><strong>如何预测犯罪？</strong></p>\n<p>综合目前AI预测犯罪的类型大致可分为两种。一种是预测犯罪热点，像是ShotSpotter公司开发的枪声感测器网路系统：感测器网路分布于城市内，据称能精确侦测到10英尺左右的枪击位置，还能即时有效地提供警方关于枪械的信息。与传统网路不同的是，他们可以测量到各种武器的脉冲声音，包括爆炸，因此被称为是广泛性的防护系统。</p>\n<p>[&#8230;]</p>\n<p>另一种则是预测犯罪嫌疑人，例如Northpointe公司的替代性惩处受刑人管理剖析量表（Correctional Offender Management Profiling for Alternative Sanctions简称 COMPAS），这是针对受刑人的侧写评估。通过测量社会经济地位、家庭背景、就业状况等因素，预测个人未来犯罪风险的可能性。此量表计算出的分数会提供给法官，判断是否适合保释，以及衡量刑期。</p>\n<p>[&#8230;]</p>\n<p><strong>COMPAS的批评</strong></p>\n<p>此外，受到最多挑战的，是使用最广泛的COMPAS。由于COMPAS的演算法并未公开，遂变成诉讼攻防的一环。2013年美国威斯康星州法庭对驾驶赃车且企图逃逸的被告Eric Loomis进行判决，法官审酌COMPAS给出的分数，判处Loomis六年监禁。Loomis的律师不服，认为违反了被告的正当程序权利，因为COMPAS阻止被告挑战此类科学评估的有效性，因此上诉到最高法院。</p>\n<p>然而上诉遭到驳回，最高法院不认为采用COMPAS是秘密而不透明的审判流程，因为评估的方法既未向判决庭也未向被告披露。另外，最高法院认为LoomisCOMPAS信息来源乃是被告提供与公开的资料，故而断定使用COMPAS并不违法，且判决庭对信息有自由裁量权，强化了COMPAS的正当性。</p>\n<p>但是，去年ProPublica网站的记者们做了实验，检视COMPAS 分类的两种被告（普通累犯和暴力累犯）。他们以佛罗里达州布劳沃德县的一万多名刑事被告为标的，将这些人被预测的“再犯率”与“两年内实际发生率”进行比较，结果发现预测普通累犯的准确度约为六成，而暴力累犯只有两成。</p>\n<p>此外，COMPAS的演算法不包括种族，但COMPAS赋予不同肤色被告的风险评分（1~10分，最高风险为10分）比率，与实际再犯率之间有著惊人的误差。要强调的是，这里的肤色被告评分的分组，是ProPublica记者们自己采用被告资料做出的结果。</p>\n<p>就普通累犯来看，被评为低风险的非裔美国人被告，实际上再犯的比例约为28%，白人约为48%。也就是说，若以肤色检视预测结果，便可以看出误差。COMPASS格外容易将非裔美国人被告视为未来的罪犯，白人被告则相反。</p>\n<p>这样的结论毫无意外地引来了Northpointe公司的反击，以COMPAS量表上获得7分的被告为例，60％的白人会再犯罪，这与非裔美国人的61%几乎完全相同。</p>\n<p>一些专家也加入讨论，有的认为ProPublica记者的报告是基于错误的统计资料和分析，有的则指出两方的论战其实是对于公平定义的歧见。</p>\n<p>重点是，COMPAS对于累犯的风险预测并未考虑肤色种族，那么为什么还会出现评分误差呢？这是因为在佛州当地，非裔美国人被告的整体再犯率高于白人被告，约52％对39％（与美国全国平均相等）。越多的非裔美国人被逮捕，会让演算法判断具有相似条件的人再犯比率更高，自然越容易给予高风险评比。</p>\n<p>由于非裔美国人社区的警务较重，或警方在决定逮捕时存在偏见，因此非裔美国人可能比犯同样罪行的白人更常被捕。这显示COMPAS受限于执法单位对于公共安全的权衡。</p>\n<p>对于这种“变相的”歧视，许多公民团体都强烈批评执法单位利用AI便宜行事，短期或者可压低犯罪率，但长期来看，预防犯罪的边际效益必然递减。</p>\n<p><strong>阻止AI学会歧视</strong></p>\n<p>为了避免这些情形加剧、也为了保障数字时代的人权，公民团体展开与警方的法律战。像是去年在芝加哥，一群记者对当地警方的犯罪热榜（heat list）提起诉讼，要求公开热榜搜集哪些资料与使用方式，洛杉矶、纽奥良、纽约等城市也都有类似的官司正在审理当中。</p>\n<p>无论这些判决结果为何，都不能完全否定AI对执法单位的作用。但不可讳言的是，犯罪预测已到了必须重新检讨的时刻：演算法所采用的许多资料参杂著警务和司法系统的既有观点，而这些AI的预测结果将反过来加深执法人员的偏见。</p>\n<p>[&#8230;]</p>\n<p>以预防代替预测</p>\n<p>随著深度学习的进化，AI预测犯罪的准确度或许能逐步提升，但实际上可能无法预防犯罪。知道何时可能发生犯罪，与解决犯罪问题其实是两回事。对比美国一些预测犯罪的做法，加拿大有另一套逻辑，多伦多警方没有加强巡逻，而是使用预测模型将社区居民与社会服务联系起来。</p>\n<p>加拿大政府希望利用数据建立更安全的社区，因为真正能减少犯罪的策略，应是让有可能成为再犯者或即将铤而走险的边缘人，获得社会服务和就业援助，而不是在已陷入困境的社区采取更严厉的打击。</p>\n<p>进一步而言，预测犯罪不该只是司法部门的任务，公民社会也该加入政策运作。例如社区经营的公共空间可以用来克制犯罪、紧密频繁的社交活动有助于预防犯罪。针对累犯，特别是暴力犯的预测型监管措施，更需要在地社区的配合，如布署小型的康复中心，以在地化的角度协助累犯重新融入社会，亦保障社区安全。</p>\n<p>（节选）</p>\n","author":996,"categories":[18271,18270,18269,18424],"tags":[36503,26675,33699,33927,26554,33617,36745]}