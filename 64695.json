{"id":64695,"link":"https://chinadigitaltimes.net/chinese/2010/04/增大awstats的limitflush，减少磁盘临时文件读写-flush-history-file-on-disk-unique-url-reach-flush-limi/","date":"2010-04-29T10:20:05Z","modified":"2010-04-29T10:20:05Z","title":"增大AWStats的$LIMITFLUSH，减少磁盘临时文件读写 Flush history file on disk (unique url reach flush limit of 5000)","content":"<p>Phase 2 : Now process new records (Flush history on disk after 20000 hosts)&#8230;<br />\nFlush history file on disk (unique url reach flush limit of 5000)<br />\nFlush history file on disk (unique url reach flush limit of 5000)<br />\nFlush history file on disk (unique url reach flush limit of 5000)<br />\n是AWStats统计常见的输出，每行都是在处理完一定数量的URL(缺省是5000个)后，AWStats将统计结果临时写入磁盘。最近使用<a href=\"http://www.chedong.com/blog/archives/001293.html\">AWStats处理百M级别</a>的日志时：磁盘IO居然非常高，<br />\n发现有时候遇到页面URL个数非常多的时候（比如：在搜索引擎蜘蛛对网站进行<a href=\"http://www.dbanotes.net/web/google_deep-web_crawl.html\">深度遍历deep crawl</a>时），经常会使得AWStats对缓存文件的读写过于频繁，随着生成的数据文件越来越大，每次几百M的临时文件读写也会导致统计速度越来越慢；经常一次统计数据下来会Flush history file on disk (unique url reach flush limit of 5000) 几百次；</p>\n<p>记得以前是对AWStats进行过简单的参数配置的，可以修改flush的周期，但现在的文档中没有找到相应的配置，只好Hack了一下：awstats.pl文件将每隔发现5千个新链接改为5万个；</p>\n<blockquote><p>&gt; $LIMITFLUSH=5000;                                     # Nb of records in data arrays after how we need to flush data on disk<br />\n&#8212;<br />\n&lt; $LIMITFLUSH=50000;                                    # Nb of records in data arrays after how we need to flush data on disk</p></blockquote>\n<p>\n其实内存够用的话，将这个值设置的更高也是没有问题的。根据观察临时文件生成的次数也相应的有数量级的下降；这个参数和<a href=\"http://www.chedong.com/tech/lucene.html#hacking\">Lucene中的merge_factor</a>有点像，都是拿内存换速度；</p>\n","author":176,"categories":[9203],"tags":[5908]}