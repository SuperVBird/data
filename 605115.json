{"id":605115,"link":"https://chinadigitaltimes.net/chinese/2019/01/视角杂志-在数字监控时代我们还能做点什么？/","date":"2019-02-01T04:55:37Z","modified":"2019-02-01T04:55:37Z","title":"视角杂志 | 在数字监控时代我们还能做点什么？","content":"<p>在信用制普及的国家，银行早已开始通过数据与算法评估用户信用。在中国，社会信用体系会在2020年强制执行，以评估13亿公民的可信度。无论喜欢与否，中国的每一位公民和法人的行为都将被评级和排名。</p>\n<p>编者按：</p>\n<p>在互联网世界，贩卖用户隐私在内的数据生意早已不是秘密，互联网由最初的匿名转向实名制，也由90年代的乌托邦设想演变为数字控制与监视的工具。如果没有相应的权力制衡，个人信息的大数据极易被寡头收割和利用。剑桥分析（Cambridge Analytica）利用Facebook用户数据操纵2016年的美国大选，这一事件已充分展示了数字控制对现实世界的影响。</p>\n<p>今天的文章将讨论，数字监控如何作用于我们的生活，我们又该如何应对。</p>\n<p>1.你的数字身份</p>\n<p>根据卢西亚诺•弗洛里迪（Luciano Floridi，牛津大学信息哲学与伦理学教授、互联网研究所研究主任）的说法，三个关键的“去中心化转移”（de-centering shifts）改变了人类对自我的认知: 哥白尼的“太阳中心说”模型，达尔文的自然选择理论，以及弗洛伊德关于我们的日常行为是由潜意识控制的说法。</p>\n<p>弗洛里迪认为，现在已经进入了第四个转变，线上和线下的行为共同融合为我们的连线生活（onlife）。他断言，社会正趋向于一个实体与虚拟混合的信息空间，我们正在获得一种连线生活的人格，这与我们在&#8221;真实世界&#8221;中的人格并不相同。Facebook与朋友圈等社交平台放大了这种连线生活的人格，人们在上面展示自己编辑与美化过的生活，网络空间不再仅仅是一种逃离真实世界的方式。<br />\nFacebook刚刚被卷入数据泄漏的丑闻之中，后果仍然在持续发酵。来源：谷歌</p>\n<p>在你不知情的情况下，你的信息已被详细记录于某个数据库，填充为数字档案，这份档案可以被拿来评估你的健康程度、财务状况或生活习惯等。甚至雇主也可能利用秘密算法监视与评判你的行为， Intermex 公司（一家国际电汇服务公司）的一位前职员声称，她因为关闭了一个应用程序而被解雇，这个应用程序能让该公司不断追踪她的位置。</p>\n<p>信用、网络、位置、购物等等数据在线上组成了我们的数字第二身份，但是这个身份组成的新世界却完全可以毁掉你的现实生活。</p>\n<p>一位女性被一家数据中间商（private data broker，负责对收集到的消费者数据进行分析与分销）错误地指控为冰毒经销商，艰难熬过房东和银行拒绝为她提供住房和信贷许多年，她才终于洗脱了自己的嫌疑。在信用制度已经普及的国家，由于错误或数据被不公正处理，借款人一生平均可能损失数万美元。</p>\n<p>政府数据库的准确度可能更为糟糕，比如在美国，“可疑活动报告”（SARs）或者不准确的逮捕记录时有被扣在无辜者头上， 这个问题很久以来一直困扰着公众。 国家和市场操纵者的海量数据意味着虚构的报告能迅速传播开，但纠正却需要数月或数年的法律工作和宣传，这种缺陷根植于数据评判系统的设计。</p>\n<p>缺陷之处在于信用算法被粗暴地简化，无法考虑到复杂环境。例如“赖帐”的人可能是因为住院而错过时间，“信用良好”的人也可能只是个吃白食的。 这就是我们所有人在数字世界里面临的挑战。如果这套控制生命的算法继续存在，我们就需要弄清楚它如何能够接受人类内在的细微差别、不一致和矛盾，以及它们对现实生活如何反应。</p>\n<p>算法同时也容易变为深化偏见的高级工具。当个人偏好被用于广告和内容推荐时，它可以重现和加强我们的偏见。为了让用户花费更多的时间在自己的平台上，公司会通过算法过滤出用户想看到的信息，让用户处于自己的文化与价值观的泡沫中。左翼政治与互联网活动家伊莱·帕里泽（Eli Pariser）在2011年同名著作中将这种现象称为过滤泡沫，现在已经在迅速加深政治两极分化。</p>\n<p>数字化的我们已经被算法所包围。我们是一个良民、一个可信之人，还是一个威胁、一个隐患，这些都由数据和算法来决定。算法成为了权力的直接掌管者，甚至能够决定我们看见什么、思考什么。</p>\n<p>2.政府：驯服的游戏化</p>\n<p>对于被分类的我们来说, 还没有有效的方式能让算法对这种分类负责。不仅如此，当算法的决策与我们的生活互动之后，我们甚至难以想到要对算法进行问责。</p>\n<p>美国国会于1970年通过了《公平信用报告法》(Fair Credit Reporting Act) ，以管理信贷局收集数据的做法，建立问责制、公平机制和补救机制。从《公平信用报告法》开始，美国监管机构常常鼓励企业使用算法做出决策，初衷便是避免人类决策者的非理性或潜意识偏见。</p>\n<p>但算法的设计者，使用者和调整者仍然都是人类。算法无法逃离现实社会的弊端，因为收集的个人和社会数据便来自这个存在歧视的社会。基于数据与算法的决策只不过是将人的观念转换为了一串串代码和参数，被转换的也包括了现实世界中的各类歧视。人脑的偏见常常来源于将“因果关系”替换为简单的相关，而基于相关性的算法只会强化相应的偏见。</p>\n<p>更揪心的是，商业跟踪和政府监控之间薄薄的界限越来越薄。讽刺网站洋葱报（The Onion ）曾经发表过一篇文章，题为《中央情报局的‘脸书’计划大大降低了中情局的成本》。现实也只是一步之遥。 斯诺登泄露的文件说明美国国家安全局会利用广告cookies收集个人信息，黑客攻击和数据搜集也被同时纳入公司的商业计划和国家的政治战略。</p>\n<p>世界各国政府都早已开始监控和评级。在美国，国家安全局(NSA)并不是唯一关注国民行为的官方监视机构。2015年，美国运输安全管理局提出了扩大 PreCheck （允许指定的飞行常客在国内旅行期间独享快速安检的权益）背景调查的构想，社交媒体记录、地理位置数据和购买记录都包括在内。这个想法被严厉抗议后搁浅了，但这并不意味着它已经死了。中美的情况正在趋同——信用评分的扩大进入生活，即使我们对此还一无所知。</p>\n<p>中国缺乏国家信贷体系，央行拥有8亿人的财务数据，但只有3.2亿人有传统的信用记录 。根据中国商务部的数据，由于缺乏信贷信息，年度经济损失超过6000亿元。这就是为什么政府坚持认为公民评分早就应该实施，而且迫切需要解决&#8221;信任赤字&#8221;。王淑芹教授最近赢得了帮助政府开发&#8221;中国社会信用系统&#8221;的竞标，“大多数人的行为取决于他们的思想境界，一个相信社会主义核心价值观的人会更体面”，王教授认为——而金融体系所评估的“道德标准”以及金融数据则是一份奖励。</p>\n<p>想象一下，根据政府制定的规则，所有行为都将有可能被评定为正面或者负面，并在这套信用体系中提炼成一个数字。这会成为你的公民评分，告诉每个人你是否值得信赖。另外，你的评分会被公开地与所有人的排名相比，用来决定你是否有资格获得抵押贷款或工作，你的孩子可以去哪里上学，能否拿到户口，甚至你能否有机会约会（参见百合网支持芝麻信用）。</p>\n<p><strong>政府不再通过大棒和自上而下的恐惧维持稳定与顺从，而是试图把驯服变得更像游戏。</strong>这是一种在部分地区探索出的社会控制方法——奖励制度。真正的问题在于: 一个人自己的分数不仅仅取决于自己，也会受到他们网友言行的影响。 如果身边有人在网上发布负面评论， 他们自己的评分也会被拖下水。</p>\n<p>这就是服从的游戏化。谁会公开批评这个体系呢？ 叮——你的分数可能会下降。令人担忧的是，很少有人明白，不好的分数将来会伤害到他们。更令人担忧的是，有多少人还不知道自己在被评价。</p>\n<p>3.学术界：算法问责的尝试</p>\n<p>2013年纽约大学举行的&#8221;管理算法&#8221;会议上, 一个由学者和活动家组成的社区对算法的输出进行了批判性地分析。现在他们正在推动一场关于算法问责的强有力的对话, 简称# algacc。像2000年代的“知识无界”（A2K，由认为获得知识应与正义、自由和经济发展的基本原则联系起来的的民间社会团体、政府和个人的松散集合）动员一样, algacc 把焦点转向了2010年代的一个关键性的社会公正问题——算法的透明。</p>\n<p>很多商界人士更想看到这场运动早点夭折，保险公司、银行和大型企业的发言人和说客普遍认为，关键算法应该得到商业保密协议的严格保护，永远不能被外人审查，更不用说批评。他们有很充足的理由——如果你知道在黑匣子内发生了什么，系统可能会被操纵或被黑客攻击。根据现行法律，这种知识产权也确实被保护得很好。</p>\n<p>但如果人类被限制于这样一个严密的评分系统内，那么评分的方式必须是透明的。当一个重要的决策者决定使用一个数据库时，Ta就应该向被排名和评级的人们解释数据的使用情况、分析方式，以及如何识别、纠正、质疑可能出现的错误、偏见或违法行为。</p>\n<p>事实上，在算法决策的每个阶段，简单的法律改革都可以为算法时代带来基本的保护。公众也可以参与对算法的问责和改革的推进。例如在美国，社会活动者可以与法律学者合作，通过《信息自由法》（Freedom of Information Act，颁布于1967年，是美国关于联邦政府信息公开化的行政法规）和公平的数据实践来揭示算法某些方面。而记者则可以与程序员和社会学家合作，不断揭露侵犯隐私的数据收集、分析和使用的技术，并推动监管机构打击那些突破底线的人。</p>\n<p>有些算法研究人员在分析现有数据之外，更进了一步，与民间监管机构、档案管理员、致力于开放数据的活动家和公共利益律师结为联盟，确保用于分析、聚合、批评的原始材料能考虑到多方意见。社会学家和其他人也需要投入到这个异常重要的长期项目里，确保算法产生的文档足够公正，否则国家、银行、保险公司和其他势力将会制造出更多秘密档案。</p>\n<p>算法问责是一个大型的公众项目，需要伦理学、哲学、法学、社会学、新闻调查、社会活动等等不同领域的人来各显神通。这是所有人都需要面对的事业，它迫在眉睫，很多致力于此的专家也在寻求更广泛的支持。如果我们不保持警惕， “分布式信任”就会变成“网络化耻辱”。生活将成为一场无休止的人气竞赛，我们都在争夺只有极少数人才能获得的最高评价，就像《黑镜》里预言的那样。</p>\n<p>4.技术：夺回你的隐私权</p>\n<p>我们的未来， 是否都将被贴上网络和数据挖掘的烙印？也许现在还为时尚早，我们并不了解监控与信息评估无处不在的文化会是怎样。但这种趋势正在蔓延，当这些系统绘制出全人类的社会、道德和金融历史时，未来会发生什么？ 隐私和言论自由还要被损害多久？ 谁来决定这个系统走哪条路？ 这些问题很快便要被纳入考虑。</p>\n<p>对隐私的保护不仅使个人受益，它从根本上塑造了社会的功能。对于社会边缘的社区和社会运动，例如争取婚姻平等和其他曾被污名化的观点，隐私是必要的。对个人隐私的保护使这些群体在改变现状之前能够建立网络，组织和发展他们的想法与平台。但是当人们知道他们被跟踪和监视时，他们就会改变他们的行为。这种令人不寒而栗的影响损害了我们的知识自由和社会进步的能力。</p>\n<p>除非有大规模的公民为了夺回隐私权而抗议，否则我们将进入一个个人行为被他们无法控制的标准所判断的时代， 而且这种判断无法被消掉。后果不仅令人不安，而且是永久性的。忘记了删除或被遗忘的权利，只剩年轻和愚蠢。</p>\n<p>好消息是，技术也可以有效地防止被跟踪。广告拦截器和其他浏览器的隐私工具可以减少超过一半的跟踪，使用更复杂的工具，如 Tor 浏览器会更有效。换句话说，技术更娴熟的人可以享受更好的隐私和数字自由。但这将导致了技术上的“军备竞赛”，这本身就令人担忧，不过这种技能也的确与那些占据优势的技术党相关。与此同时，出版商被广告拦截器等工具误伤，危及自由媒体。</p>\n<p>虽然现在停止这个新时代可能已经太晚了，但我们现在确实有选择和权利可以利用。比如，我们需要对评级人员进行评估。凯文·凯利在他的书《不可避免》中描述了一个未来， 在那里，观察者和被监视者将透明地相互跟踪。他写道：“我们现在的核心选择是，这种监视是一种秘密的单向监视，还是一种相互透明（同时监视观察者）的‘贪婪’”。</p>\n<p>参考资料</p>\n<p>https://aeon.co/essays/judge-jury-and-executioner-the-unaccountable-algorithm</p>\n<p>https://aeon.co/essays/the-strange-benefits-of-living-in-a-total-surveillance-state</p>\n<p>http://www.wired.co.uk/article/chinese-government-social-credit-score-privacy-invasion</p>\n<p>https://www.theatlantic.com/technology/archive/2017/05/the-thinning-line-between-commercial-and-government-surveillance/524952/</p>\n<p>编译：子川</p>\n<p>老掉了的朋克，开源社区推广者</p>\n<p>文章首图/尾图：Kaethe Kollwitz Edward Hopper</p>\n<p>文章来源：wired /the atlantic/aeon</p>\n<p>图片来源：网络</p>\n<p>编辑：刘果 严妍</p>\n<p>校对：刘果</p>\n<p>排版：付安琪</p>\n","author":1060,"categories":[18270,18269,9203,10466],"tags":[34394,8686,37841]}